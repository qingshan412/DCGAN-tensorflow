I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcurand.so.8.0 locally
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB
major: 6 minor: 0 memoryClockRate (GHz) 1.3285
pciBusID 0000:02:00.0
Total memory: 15.89GiB
Free memory: 15.61GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x2c6a850
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 1 with properties: 
name: Tesla P100-PCIE-16GB
major: 6 minor: 0 memoryClockRate (GHz) 1.3285
pciBusID 0000:03:00.0
Total memory: 15.89GiB
Free memory: 15.61GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x2c6e1d0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 2 with properties: 
name: Tesla P100-PCIE-16GB
major: 6 minor: 0 memoryClockRate (GHz) 1.3285
pciBusID 0000:82:00.0
Total memory: 15.89GiB
Free memory: 15.61GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x2c71b50
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 3 with properties: 
name: Tesla P100-PCIE-16GB
major: 6 minor: 0 memoryClockRate (GHz) 1.3285
pciBusID 0000:83:00.0
Total memory: 15.89GiB
Free memory: 15.61GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 0 and 2
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 0 and 3
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 1 and 2
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 1 and 3
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 2 and 0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 2 and 1
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 3 and 0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 3 and 1
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 1 2 3 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y Y N N 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 1:   Y Y N N 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 2:   N N Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 3:   N N Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:02:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:03:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla P100-PCIE-16GB, pci bus id: 0000:82:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:3) -> (device: 3, name: Tesla P100-PCIE-16GB, pci bus id: 0000:83:00.0)
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
Traceback (most recent call last):
  File "main_l3.py", line 96, in <module>
    tf.app.run()
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/master-branch/python2/build/lib/python2.7/site-packages/tensorflow/python/platform/app.py", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File "main_l3.py", line 93, in main
    visualize(sess, dcgan, FLAGS, OPTION)
  File "/afs/crc.nd.edu/user/j/jliu16/Private/Research/2017/DCGAN/DCGAN-tensorflow/utils.py", line 174, in visualize
    samples = sess.run(dcgan.sampler, feed_dict={dcgan.z: z_sample})
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/master-branch/python2/build/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 767, in run
    run_metadata_ptr)
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/master-branch/python2/build/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 965, in _run
    feed_dict_string, options, run_metadata)
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/master-branch/python2/build/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1015, in _do_run
    target_list, options, run_metadata)
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/master-branch/python2/build/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1035, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
	 [[Node: generator_1/Tanh/_167 = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_95_generator_1/Tanh", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/cpu:0"]()]]

Caused by op u'generator_1/g_h1/conv2d_transpose', defined at:
  File "main_l3.py", line 96, in <module>
    tf.app.run()
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/master-branch/python2/build/lib/python2.7/site-packages/tensorflow/python/platform/app.py", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File "main_l3.py", line 76, in main
    sample_dir=FLAGS.sample_dir)
  File "/afs/crc.nd.edu/user/j/jliu16/Private/Research/2017/DCGAN/DCGAN-tensorflow/model_l3.py", line 75, in __init__
    self.build_model()
  File "/afs/crc.nd.edu/user/j/jliu16/Private/Research/2017/DCGAN/DCGAN-tensorflow/model_l3.py", line 121, in build_model
    self.sampler = self.sampler(self.z)
  File "/afs/crc.nd.edu/user/j/jliu16/Private/Research/2017/DCGAN/DCGAN-tensorflow/model_l3.py", line 447, in sampler
    h1 = deconv2d(h0, [self.batch_size, s_h4, s_w4, self.gf_dim*4], name='g_h1')
  File "/afs/crc.nd.edu/user/j/jliu16/Private/Research/2017/DCGAN/DCGAN-tensorflow/ops.py", line 75, in deconv2d
    strides=[1, d_h, d_w, 1])
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/master-branch/python2/build/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py", line 1077, in conv2d_transpose
    name=name)
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/master-branch/python2/build/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py", line 489, in conv2d_backprop_input
    data_format=data_format, name=name)
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/master-branch/python2/build/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py", line 763, in apply_op
    op_def=op_def)
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/master-branch/python2/build/lib/python2.7/site-packages/tensorflow/python/framework/ops.py", line 2395, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/master-branch/python2/build/lib/python2.7/site-packages/tensorflow/python/framework/ops.py", line 1264, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): Conv2DSlowBackpropInput: input and out_backprop must have the same batch size
	 [[Node: generator_1/g_h1/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](generator_1/g_h1/conv2d_transpose/output_shape, generator/g_h1/w/read, generator_1/Relu)]]
	 [[Node: generator_1/Tanh/_167 = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_95_generator_1/Tanh", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/cpu:0"]()]]

